{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47d1ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import timedelta\n",
    "import boto3\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e11291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/cedrix/Documents/aws.json', 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = credentials ['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = credentials ['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "# AWS S3 bucket\n",
    "bucket = 'raw-stock-price'\n",
    "\n",
    "# Load data from S3\n",
    "  \n",
    "def load_data_from_s3(file_name):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=credentials['AWS_ACCESS_KEY_ID'], aws_secret_access_key=credentials['AWS_SECRET_ACCESS_KEY'])\n",
    "    obj = s3.get_object(Bucket=bucket, Key=file_name)\n",
    "    df = pd.read_csv(obj['Body'])\n",
    "    print(\"NaN values in data after loading:\", df.isnull().sum().sum())\n",
    "    return df\n",
    "\n",
    "# Function to list all files in a specific S3 bucket folder\n",
    "def list_files_in_s3_bucket(bucket_name, prefix):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=credentials['AWS_ACCESS_KEY_ID'], aws_secret_access_key=credentials['AWS_SECRET_ACCESS_KEY'])\n",
    "    response = s3.list_objects(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "    # Get a list of all the file names\n",
    "    files = [item['Key'] for item in response['Contents']]\n",
    "\n",
    "    # Extract the stock symbol from each file name\n",
    "    stock_symbols = [file.split('/')[-1].split('_')[0] for file in files]\n",
    "\n",
    "    return stock_symbols\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.dropna(inplace=True)  # Drop rows with missing data\n",
    "    return df\n",
    "\n",
    "def add_feature(df, feature, window):\n",
    "    if feature == 'MA':\n",
    "        close_col = df['adj_close']\n",
    "        df['MA'] = close_col.rolling(window=window).mean()\n",
    "    if feature == 'EMA':\n",
    "        close_col = df['adj_close']\n",
    "        df['EMA'] = close_col.ewm(span=window, adjust=False).mean()\n",
    "    if feature == 'SO':\n",
    "        high14 = df['high'].rolling(window).max()\n",
    "        low14 = df['low'].rolling(window).min()\n",
    "        df['%K'] = (df['close'] - low14) * 100 / (high14 - low14)\n",
    "        df['%D'] = df['%K'].rolling(3).mean()\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df.dropna(inplace=True)\n",
    "        \n",
    "    if df.isnull().values.any():\n",
    "        print(f\"NaN values introduced after adding {feature}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, metric):\n",
    "    predictions = model.predict(X_test)\n",
    "    if metric == 'rmse':\n",
    "        return np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(y_test, predictions)\n",
    "    elif metric == 'mape':\n",
    "        return np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "    else:\n",
    "        print(f\"Metric {metric} not recognized\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5df95a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "        \n",
    "        \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def test_create_dataset():\n",
    "    # Create a simple DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'A': range(10),\n",
    "        'B': range(10, 20),\n",
    "        'C': range(20, 30)\n",
    "    })\n",
    "\n",
    "    # Create X and y\n",
    "    X = df[['A', 'B']]\n",
    "    y = df['C']\n",
    "\n",
    "    # Call create_dataset\n",
    "    Xs, ys = create_dataset(X, y, time_steps=3)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Xs:\")\n",
    "    print(Xs)\n",
    "    print(\"ys:\")\n",
    "    print(ys)\n",
    "\n",
    "    # Call the test function\n",
    "    test_create_dataset()\n",
    "    \n",
    "def reshape_data(data, time_steps=1):\n",
    "    # Insert your choice of padding here. I'll use 0.\n",
    "    padding = np.zeros((time_steps - 1, data.shape[1]))\n",
    "    data = np.concatenate([padding, data])\n",
    "    reshaped_data = np.array([data[i:i + time_steps] for i in range(data.shape[0] - time_steps + 1)])\n",
    "    return reshaped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f420d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(df, future_days, test_size, lstm_units, dropout, epochs, batch_size):\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Apply shift operation\n",
    "        df['Prediction'] = df['adj_close'].shift(-future_days)\n",
    "\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # Create X_predict using the shifted copy\n",
    "        X_predict = np.array(df_copy.drop(['Prediction'], 1))[-future_days:]\n",
    "        X_predict = np.array(df.drop(['Prediction'], 1))[-future_days:]\n",
    "\n",
    "        X = df.drop(['Prediction'], axis=1)\n",
    "        X = X[:-future_days]\n",
    "        y = df['Prediction']\n",
    "        y = y[:-future_days]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        \n",
    "        print(\"NaN values in X_train:\", np.isnan(X_train).sum())\n",
    "        print(\"NaN values in X_test:\", np.isnan(X_test).sum())\n",
    "        print(\"NaN values in y_train:\", np.isnan(y_train).sum())\n",
    "        print(\"NaN values in y_test:\", np.isnan(y_test).sum())\n",
    "        \n",
    "        print(\"Shape of X_train:\", X_train.shape)\n",
    "        print(\"Shape of X_test:\", X_test.shape)\n",
    "        print(\"Shape of y_train:\", y_train.shape)\n",
    "        print(\"Shape of y_test:\", y_test.shape)\n",
    "        \n",
    "        print(\"Shape of X:\", X.shape)\n",
    "        print(\"Shape of y:\", y.shape)\n",
    "        print(\"NaN values in X:\", np.isnan(X).sum())\n",
    "        print(\"NaN values in y:\", np.isnan(y).sum())\n",
    "        \n",
    "        \n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        time_steps = 1\n",
    "        X_train, y_train = create_dataset(pd.DataFrame(X_train), pd.DataFrame(y_train), time_steps)\n",
    "        X_test, y_test = create_dataset(pd.DataFrame(X_test), pd.DataFrame(y_test), time_steps)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(LSTM(units=lstm_units))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_param(\"future_days\", future_days)\n",
    "            mlflow.log_param(\"test_size\", test_size)\n",
    "            mlflow.log_param(\"lstm_units\", lstm_units)\n",
    "            mlflow.log_param(\"dropout\", dropout)\n",
    "            mlflow.log_param(\"epochs\", epochs)\n",
    "            mlflow.log_param(\"batch_size\", batch_size)\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_split=0.2,\n",
    "                callbacks=[es],\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "            # Log model\n",
    "            mlflow.keras.log_model(model, \"lstm\")\n",
    "\n",
    "            # Log metrics: RMSE, MSE and MAPE\n",
    "            rmse = math.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "            mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "            mape = mean_absolute_percentage_error(y_test, model.predict(X_test))\n",
    "\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            mlflow.log_metric(\"mape\", mape)\n",
    "\n",
    "        return model, X_train, X_test, y_train, y_test, X_predict, scaler\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        mlflow.end_run()\n",
    "        \n",
    "        \n",
    "        \n",
    "def run_model(file_name, ma_window=5, lstm_units=50, dropout=0.2, epochs=100, batch_size=32, test_size=0.2, future_days=30, rmse=True, mse=True, mape=True, display_at=0):\n",
    "    try:\n",
    "        # Load data from S3\n",
    "        df = load_data_from_s3(file_name)\n",
    "        print(\"NaN values in data after preprocessing:\", df.isnull().sum().sum())\n",
    "\n",
    "\n",
    "\n",
    "        # Preprocess data\n",
    "        df = preprocess_data(df)\n",
    "        print(\"NaN values in data after preprocessing:\", df.isnull().sum().sum())\n",
    "\n",
    "        # Define feature windows\n",
    "        feature_windows = {\n",
    "            'MA': ma_window,\n",
    "        }\n",
    "\n",
    "        # Add features to the data\n",
    "        for feature in feature_windows:\n",
    "            print(f\"NaN values in data after adding {feature}:\", df.isnull().sum().sum())\n",
    "            df = add_feature(df, feature, feature_windows[feature])\n",
    "\n",
    "        # Train model and evaluate\n",
    "        model, X_train, X_test, y_train, y_test, X_predict, scaler = train_model(df, future_days, test_size, lstm_units, dropout, epochs, batch_size)\n",
    "        evaluations = {}\n",
    "        if rmse:\n",
    "            evaluations['rmse'] = evaluate_model(model, X_test, y_test, 'rmse')\n",
    "        if mse:\n",
    "            evaluations['mse'] = evaluate_model(model, X_test, y_test, 'mse')\n",
    "        if mape:\n",
    "            evaluations['mape'] = evaluate_model(model, X_test, y_test, 'mape')\n",
    "\n",
    "            \n",
    "        # Print the dataframe before dropping the 'Prediction' column\n",
    "        print(df)\n",
    "\n",
    "        # Check if 'Prediction' column exists in the dataframe\n",
    "        if 'Prediction' in df.columns:\n",
    "            print(\"Prediction column exists in the dataframe.\")\n",
    "        else:\n",
    "            print(\"Prediction column does not exist in the dataframe.\")   \n",
    "            \n",
    "        \n",
    "        # Generate prediction\n",
    "        lstm_model_real_prediction = model.predict(np.array(df.drop(['Prediction'], 1)))\n",
    "        \n",
    "        data = data.reshape((data.shape[0], 1, data.shape[1]))\n",
    "\n",
    "        lstm_model_real_prediction = model.predict(data)\n",
    "        \n",
    "        \n",
    "        # Plot\n",
    "        plot_results(df, lstm_model_real_prediction, lstm_model_predict_prediction, display_at, future_days)\n",
    "\n",
    "        return model, evaluations, df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None, None  # return None for each expected return value\n",
    "    finally:\n",
    "        mlflow.end_run()\n",
    "        \n",
    "        \n",
    "def plot_results(df, lstm_model_real_prediction, lstm_model_predict_prediction, display_at, future_days):\n",
    "    predicted_dates = [df.index[-1] + timedelta(days=x) for x in range(1, future_days+1)]\n",
    "    fig, ax = plt.subplots(figsize=(40, 20))\n",
    "\n",
    "    # Change the background color to black\n",
    "    plt.rcParams['figure.facecolor'] = 'black'\n",
    "    ax.set_facecolor('black')\n",
    "    ax.tick_params(colors='white')\n",
    "    ax.xaxis.label.set_color('white')\n",
    "    ax.yaxis.label.set_color('white')\n",
    "\n",
    "    ax.plot(df.index[display_at:], lstm_model_real_prediction[display_at:], label='LSTM Prediction', color='magenta', linewidth=5.0)\n",
    "    ax.plot(predicted_dates, lstm_model_predict_prediction, label='Forecast', color='aqua', linewidth=5.0)\n",
    "    ax.plot(df.index[display_at:], df['adj_close'][display_at:], label='Actual', color='lightgreen', linewidth=5.0)\n",
    "\n",
    "    # Format the x-axis dates\n",
    "    date_format = DateFormatter(\"%Y-%m-%d\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "\n",
    "    plt.legend(prop={'size': 35})  # Increase the size of the legend\n",
    "    plt.xticks(fontsize=30)  # Increase x-axis font size\n",
    "    plt.yticks(fontsize=30)  # Increase y-axis font size\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "# model, evaluations, df = run_model(\n",
    "#     file_name='yhoofinance-daily-historical-data/TSLA_daily_data.csv', \n",
    "#     ma_window=5, \n",
    "#     lstm_units=50, \n",
    "#     dropout=0.2, \n",
    "#     epochs=100, \n",
    "#     batch_size=32, \n",
    "#     test_size=0.2, \n",
    "#     future_days=30, \n",
    "#     rmse=True, \n",
    "#     mse=True, \n",
    "#     mape=True, \n",
    "#     display_at=0\n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ad0be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.title('LSTM Stock Price Prediction')\n",
    "     \n",
    "    st.sidebar.markdown('# Parameters')\n",
    "\n",
    "    # Get a list of all the stock symbols in the 'yhoofinance-daily-historical-data/' folder\n",
    "    stock_symbols = list_files_in_s3_bucket('raw-stock-price', 'yhoofinance-daily-historical-data/')\n",
    "\n",
    "    # Use this list to populate the dropdown menu\n",
    "    stock_symbol = st.sidebar.selectbox('Stocks', stock_symbols)\n",
    "\n",
    "    # Construct the file name from the selected stock symbol\n",
    "    file_name = f'yhoofinance-daily-historical-data/{stock_symbol}_daily_data.csv'\n",
    "    ma_window = st.sidebar.slider('Moving Avg. -- Window Size', 1, 100, 50)\n",
    "    lstm_units = st.sidebar.slider('LSTM Units', 10, 200, 50)\n",
    "    dropout = st.sidebar.slider('Dropout', 0.1, 0.9, 0.2)\n",
    "    epochs = st.sidebar.slider('Epochs', 10, 200, 100)\n",
    "    batch_size = st.sidebar.slider('Batch Size', 1, 64, 32)\n",
    "    test_size = st.sidebar.slider('Test Set Size', 0.1, 0.9, 0.2)\n",
    "    future_days = st.sidebar.slider('Days to Forecast', 1, 50, 30)\n",
    "    display_at = st.sidebar.slider('Display From Day', 0, 365, 0)\n",
    "\n",
    "    features = st.sidebar.multiselect('Features', options=['MA', 'adj_close'], default=['adj_close'])\n",
    "\n",
    "    metrics = st.sidebar.multiselect('Evaluation Metrics', options=['RMSE', 'MSE', 'MAPE'], default=['RMSE', 'MSE', 'MAPE'])\n",
    "\n",
    "    rmse = 'RMSE' in metrics\n",
    "    mse = 'MSE' in metrics\n",
    "    mape = 'MAPE' in metrics\n",
    "\n",
    "    if st.sidebar.button('Train Model'):\n",
    "        st.markdown('## Training Model...')\n",
    "\n",
    "        model, evaluations, df = run_model(\n",
    "            file_name=file_name,\n",
    "            ma_window=ma_window,\n",
    "            lstm_units=lstm_units,\n",
    "            dropout=dropout,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            test_size=test_size,\n",
    "            future_days=future_days,\n",
    "            rmse=rmse,\n",
    "            mse=mse,\n",
    "            mape=mape,\n",
    "            display_at=display_at\n",
    "        )\n",
    "\n",
    "        # Display evaluation metrics in multiple columns\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "\n",
    "        with col1:\n",
    "            st.header(\"RMSE\")\n",
    "            st.write(evaluations['rmse'])\n",
    "\n",
    "        with col2:\n",
    "            st.header(\"MSE\")\n",
    "            st.write(evaluations['mse'])\n",
    "\n",
    "        with col3:\n",
    "            st.header(\"MAPE\")\n",
    "            st.write(evaluations['mape'])\n",
    "\n",
    "        st.markdown('## Forecast Plot')\n",
    "        st.pyplot()\n",
    "\n",
    "        if model is not None:\n",
    "             st.markdown('')\n",
    "        else:\n",
    "            st.markdown('## An error occurred during model training')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0bfb73b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in data after loading: 0\n",
      "NaN values in data after preprocessing: 0\n",
      "NaN values in data after preprocessing: 0\n",
      "NaN values in data after adding MA: 0\n",
      "NaN values in X_train: open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "adj_close    0\n",
      "volume       0\n",
      "MA           0\n",
      "dtype: int64\n",
      "NaN values in X_test: open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "adj_close    0\n",
      "volume       0\n",
      "MA           0\n",
      "dtype: int64\n",
      "NaN values in y_train: 0\n",
      "NaN values in y_test: 0\n",
      "Shape of X_train: (1695, 7)\n",
      "Shape of X_test: (424, 7)\n",
      "Shape of y_train: (1695,)\n",
      "Shape of y_test: (424,)\n",
      "Shape of X: (2119, 7)\n",
      "Shape of y: (2119,)\n",
      "NaN values in X: open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "adj_close    0\n",
      "volume       0\n",
      "MA           0\n",
      "dtype: int64\n",
      "NaN values in y: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/s86qy4dx6sj5j58slv3z77840000gn/T/ipykernel_4495/2981621691.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X_predict = np.array(df_copy.drop(['Prediction'], 1))[-future_days:]\n",
      "/var/folders/q_/s86qy4dx6sj5j58slv3z77840000gn/T/ipykernel_4495/2981621691.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X_predict = np.array(df.drop(['Prediction'], 1))[-future_days:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 2s 9ms/step - loss: 21707.6094 - val_loss: 23383.2168\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 21517.8965 - val_loss: 22896.5859\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 20864.8613 - val_loss: 21944.3105\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 19978.8965 - val_loss: 21026.6035\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 19159.0488 - val_loss: 20294.3711\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 18530.9590 - val_loss: 19740.1172\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 18046.8066 - val_loss: 19299.8945\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 17662.1406 - val_loss: 18929.2305\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 17325.7754 - val_loss: 18602.8047\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 17040.6719 - val_loss: 18308.0996\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 16770.5547 - val_loss: 18036.2383\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 16545.9238 - val_loss: 17783.8828\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 16291.4199 - val_loss: 17545.2734\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 16088.4727 - val_loss: 17320.9590\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 15865.7383 - val_loss: 17107.2520\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 15672.0410 - val_loss: 16904.0957\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 15521.5518 - val_loss: 16711.6973\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 15322.4385 - val_loss: 16527.8359\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 15160.6494 - val_loss: 16352.0225\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 15021.0986 - val_loss: 16184.3604\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 14842.9814 - val_loss: 16023.5703\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 14686.2490 - val_loss: 15869.6338\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 14562.7852 - val_loss: 15722.5439\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 14479.8008 - val_loss: 15582.8965\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 14334.5137 - val_loss: 15448.5107\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 14256.9092 - val_loss: 15320.4248\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 14118.7275 - val_loss: 15197.6914\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 13988.3232 - val_loss: 15079.8438\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 13920.4648 - val_loss: 14967.7021\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 13813.6943 - val_loss: 14860.0557\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 13668.3086 - val_loss: 14756.5889\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 13663.2637 - val_loss: 14657.8467\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 13497.9629 - val_loss: 14562.8643\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 13458.7764 - val_loss: 14472.9971\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 13364.7881 - val_loss: 14387.1797\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 13254.7842 - val_loss: 14304.3877\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 13266.9902 - val_loss: 14226.1094\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 13112.5830 - val_loss: 14150.4736\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 13112.6143 - val_loss: 14078.7656\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 13064.3848 - val_loss: 14010.7285\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12983.2012 - val_loss: 13945.3994\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12923.2949 - val_loss: 13883.3555\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12875.6240 - val_loss: 13824.5801\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12874.3926 - val_loss: 13769.1533\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12778.4707 - val_loss: 13716.0000\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12687.7861 - val_loss: 13665.1709\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12623.2988 - val_loss: 13616.1387\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12634.6729 - val_loss: 13570.4053\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12657.0068 - val_loss: 13527.5576\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12584.7363 - val_loss: 13486.6621\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12538.3311 - val_loss: 13447.6641\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12531.7891 - val_loss: 13411.2090\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12471.0410 - val_loss: 13376.5117\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12451.8838 - val_loss: 13343.5254\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12460.9561 - val_loss: 13312.8750\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12516.8027 - val_loss: 13284.0645\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12489.7090 - val_loss: 13257.2979\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12427.2324 - val_loss: 13231.6240\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12320.6494 - val_loss: 13206.4795\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12365.9473 - val_loss: 13183.6162\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12367.3018 - val_loss: 13161.8906\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12387.4365 - val_loss: 13142.1650\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12321.1465 - val_loss: 13123.3301\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12204.9229 - val_loss: 13105.1914\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12235.8711 - val_loss: 13087.8086\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12298.9326 - val_loss: 13071.9355\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12275.7119 - val_loss: 13057.7285\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12200.4395 - val_loss: 13043.3789\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12252.6787 - val_loss: 13030.6416\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12225.9648 - val_loss: 13018.6670\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12271.8076 - val_loss: 13007.3760\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12219.9668 - val_loss: 12996.9053\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12257.2920 - val_loss: 12987.6074\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12179.9170 - val_loss: 12978.6787\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12204.6113 - val_loss: 12970.0205\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12235.9434 - val_loss: 12962.4023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12182.7061 - val_loss: 12954.8330\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12168.4072 - val_loss: 12947.7490\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12177.5625 - val_loss: 12941.3613\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12168.9189 - val_loss: 12935.6621\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12225.2100 - val_loss: 12930.1064\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12209.5088 - val_loss: 12924.8896\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12214.4854 - val_loss: 12920.1475\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12149.6543 - val_loss: 12915.9678\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12232.9473 - val_loss: 12911.9912\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12217.3066 - val_loss: 12908.5117\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12108.7197 - val_loss: 12904.7920\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12186.0986 - val_loss: 12901.6533\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12173.7979 - val_loss: 12898.5381\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12154.7236 - val_loss: 12895.5459\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12243.6113 - val_loss: 12893.4395\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12147.2188 - val_loss: 12890.9941\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12187.0264 - val_loss: 12888.7119\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12208.6055 - val_loss: 12886.9863\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12138.9785 - val_loss: 12884.4131\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12188.7871 - val_loss: 12882.7275\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12149.4453 - val_loss: 12881.2119\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 12086.7090 - val_loss: 12879.2578\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12184.4258 - val_loss: 12877.7578\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 12176.9238 - val_loss: 12876.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/31 15:05:04 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/q_/s86qy4dx6sj5j58slv3z77840000gn/T/tmpyozhg6kq/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/q_/s86qy4dx6sj5j58slv3z77840000gn/T/tmpyozhg6kq/model/data/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 595us/step\n",
      "14/14 [==============================] - 0s 672us/step\n",
      "14/14 [==============================] - 0s 571us/step\n",
      "14/14 [==============================] - 0s 554us/step\n",
      "14/14 [==============================] - 0s 543us/step\n",
      "14/14 [==============================] - 0s 747us/step\n",
      "                  open        high         low       close   adj_close  \\\n",
      "date                                                                     \n",
      "2015-01-08   14.187333   14.253333   14.000667   14.041333   14.041333   \n",
      "2015-01-09   13.928000   13.998667   13.664000   13.777333   13.777333   \n",
      "2015-01-12   13.536667   13.631333   13.283333   13.480667   13.480667   \n",
      "2015-01-13   13.554667   13.840667   13.394000   13.616667   13.616667   \n",
      "2015-01-14   12.388667   13.013333   12.333333   12.846000   12.846000   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2023-07-18  290.149994  295.260010  286.010010  293.339996  293.339996   \n",
      "2023-07-19  296.040009  299.290009  289.519989  291.260010  291.260010   \n",
      "2023-07-20  279.559998  280.929993  261.200012  262.899994  262.899994   \n",
      "2023-07-21  268.000000  268.000000  255.800003  260.019989  260.019989   \n",
      "2023-07-24  255.850006  262.571289  254.119995  262.549988  262.549988   \n",
      "\n",
      "               volume          MA  Prediction  \n",
      "date                                           \n",
      "2015-01-08   51637500   14.163333   13.822667  \n",
      "2015-01-09   70024500   13.994666   13.607333  \n",
      "2015-01-12   89254500   13.889600   13.584000  \n",
      "2015-01-13   67159500   13.795867   13.812667  \n",
      "2015-01-14  173278500   13.552400   13.556000  \n",
      "...               ...         ...         ...  \n",
      "2023-07-18  112434700  282.997998         NaN  \n",
      "2023-07-19  142355400  286.852002         NaN  \n",
      "2023-07-20  175158300  283.852002         NaN  \n",
      "2023-07-21  161050100  279.579999         NaN  \n",
      "2023-07-24   36639974  274.013995         NaN  \n",
      "\n",
      "[2149 rows x 8 columns]\n",
      "Prediction column exists in the dataframe.\n",
      "An error occurred: in user code:\n",
      "\n",
      "    File \"/Users/cedrix/anaconda3/envs/mlflow-mlops/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2341, in predict_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/Users/cedrix/anaconda3/envs/mlflow-mlops/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2327, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/Users/cedrix/anaconda3/envs/mlflow-mlops/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2315, in run_step  **\n",
      "        outputs = model.predict_step(data)\n",
      "    File \"/Users/cedrix/anaconda3/envs/mlflow-mlops/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2283, in predict_step\n",
      "        return self(x, training=False)\n",
      "    File \"/Users/cedrix/anaconda3/envs/mlflow-mlops/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"/Users/cedrix/anaconda3/envs/mlflow-mlops/lib/python3.11/site-packages/keras/src/layers/rnn/lstm.py\", line 616, in call\n",
      "        timesteps = input_shape[0] if self.time_major else input_shape[1]\n",
      "\n",
      "    TypeError: Exception encountered when calling layer 'lstm_34' (type LSTM).\n",
      "    \n",
      "    'NoneType' object is not subscriptable\n",
      "    \n",
      "    Call arguments received by layer 'lstm_34' (type LSTM):\n",
      "      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n",
      "      • mask=None\n",
      "      • training=False\n",
      "      • initial_state=None\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/s86qy4dx6sj5j58slv3z77840000gn/T/ipykernel_4495/2981621691.py:139: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  lstm_model_real_prediction = model.predict(np.array(df.drop(['Prediction'], 1)))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set your file path\n",
    "    file_name = 'yhoofinance-daily-historical-data/TSLA_daily_data.csv'\n",
    "    \n",
    "    # Set your parameters\n",
    "    ma_window = 5\n",
    "    lstm_units = 50\n",
    "    dropout = 0.2\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "    test_size = 0.2\n",
    "    future_days = 30\n",
    "    rmse = True\n",
    "    mse = True\n",
    "    mape = True\n",
    "    display_at = 0\n",
    "\n",
    "    # Run the model\n",
    "    model, evaluations, df = run_model(\n",
    "        file_name=file_name,\n",
    "        ma_window=ma_window,\n",
    "        lstm_units=lstm_units,\n",
    "        dropout=dropout,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        test_size=test_size,\n",
    "        future_days=future_days,\n",
    "        rmse=rmse,\n",
    "        mse=mse,\n",
    "        mape=mape,\n",
    "        display_at=display_at\n",
    "    )\n",
    "\n",
    "    # Print the evaluations\n",
    "    print(evaluations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c802b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a9474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
